# 第3章 Opteronのデータキャッシュとロードストアユニット

- 3.1 データキャッシュ: 64kBのデータ容量、データロードに3サイクルレイテンシ
- 3.2 1サイクルあたり2つの読み込みまたは書き込み発行: 8-wayバンクインターリーブ、2-wayセットアソシアティブ
- 3.3 データキャッシュヒット/ミス検出: キャッシュタグとprimairy TLB
- 3.4 512エントリのセカンドレベルTLB
- 3.5 エラーコードと訂正
- 3.6 ロードストアユニット: LS1とLS2
- 3.7 「プリキャッシュド」ロードストアユニット: LS1
- 3.8 LS2へのロード: キャッシュプローブレスポンス
- 3.9 「ポストキャッシュド」ロードストアユニット: LS2
- 3.10 ロードーストアユニット内での命令リタイアと例外処理
- 3.11 ストアフォワーディングとロードフォワーディング、依存リンクファイル
- 3.12 自己変更コードチェック: L1 DcacheとL1 Icacheの相互排他処理
- 3.13 マルチプロセッサにおけるデッドロックの処理: Exponential back-off
- 3.14 マルチプロセッシングとマルチスレッドにおける改善
- 3.15 アドレススペースナンバ(ASN)とグローバルフラグ
- 3.16 TLBフラッシュフィルタ: CAM
- 3.17 データキャッシュスヌープインタフェース
- 3.18 キャッシュコヒーレンシのためのデータキャッシュ: MOESIプロトコル
- 3.19 キャッシュコヒーレンシのためのデータキャッシュ: スヌープタグRAM
- 3.20 L1データキャッシュのスヌーピングとLS2のアウトスタンディングストア
- 3.21 共有メモリにおける厳密なメモリオーダリングのためのLS2スヌーピング
- 3.22 TLBフラッシュフィルタCAMでのスヌーピング

![Opteron's DataCache & Load/Store Units](Opteron_Data_Cache.jpg)

## 3.1 データキャッシュ: 64kBのデータ容量、3サイクルレイテンシのデータロード

Opteronは比較的大きめのL1データキャッシュサイズを持っており、「ロードユースレイテンシ」は3クロックサイクルである。
実際には、キャッシュメモリ事態にアクセスするのには2~3サイクルしか必要ない。
最初のサイクルはx86メモリアドレスを計算するために、3つのAGUのうち一つを利用してアドレス計算が行われる。
AGUにより計算されたアドレスは2サイクル目でメモリアレイに転送され、「デコードされる」。
これにより2サイクル目の最後にデータが存在する場所の「ワードライン」が検出される。

![Likely Memory Organization](Opteron_DataCacheTile.jpg)

3サイクル目に、正しいワードが有効化される。
メモリアレイ中でメモリアクセスが発生し、整数パイプライン化浮動小数点パイプラインにデータが転送される。
以下は典型的な整数x86命令であるF(reg,mem)におけるタイミングの詳細である。
このタイプの命令は最初にデータをメモリからロードし、そのデータを利用して演算を行う。

命令がスケジューラに対してディスパッチされるときに、「プリキャッシュドロードストアユニット(LS1)」に対してもディスパッチされることを見る。
このユニットに命令が挿入されると、LS2と争ってキャッシュアクセスを行う。
LS1中の命令は有効なメモリアドレスが得られるまで待つ必要があるため、AGUのリザルトバスを監視する。
LS1中の命令は、どのAGUがアドレスを供給するかを知っている。
一般的に命令は1サイクル前に供給されるリオーダバッファタグをチェックする。
一般的に、LS1中の命令はアドレスをフェッチし、キャッシュがプローブされるのを待つ。

![Likely Memory Organization](Datacache_Timing.JPG)

命令は、他の命令が待っていない限り、アドレスを計算するとその値をすぐにキャッシュ転送する。
上記の例には、2つのケースが存在する。
どのようなケースにおいても、各命令は以降のアクションに備えてアドレスを保持する。
アドレスはAGUのリザルトバスからデータキャッシュのアドレスデコーダに直接転送される。
データはメモリから1サイクルで返され整数パイプラインに渡される。
LS1はデータキャッシュのリザルトタグバスを、データが到着する1サイクル前にリオーダバッファに置く。
したがって、整数ALUスケジューラはロードデータに依存する任意の命令をスケジューリングすることができるようになる。

## 3.2 1サイクルあたり2つの読み込みまたは書き込み発行: 8-wayバンクインターリーブ、2-wayセットアソシアティブ

Opteronのキャッシュは64bitのポートを2つもっているため、1サイクルで2つのアクセスを発行できる。
どのような読み込みと書き込みのペアも実行可能だ。
デュアルポートの機構は、バンク機構を利用して実装されている: キャッシュは8つの独立したバンクを持っており、それぞれ単一のポート持っている。
2つのメモリアクセスは異なるバンクであれば同時に処理可能である。

![L1データキャッシュに利用する仮想アドレスビット](virtual_address_l1cache.JPG)

64バイトのキャッシュラインは、8つの独立した64bitのバンクに分割される。
2つのアドレスが異なるバンクフィールドを示していれば、異なるバンクに対して発行される。
このバンクフィールドは3ビット目から5ビット目である。
「データ局所性」の原理により、この構成で問題なく動作するようになっている。

64kByteのキャッシュは2-wayセットアソシアティブの構成である。
キャッシュは2つの32kByteのウェイに分割されており、これらは仮想アドレスビット[14: 0]により選択される。
物理アドレスタグ[39:12]が2つのウェイのうちどちらかにヒットしたかを検出する。
キャッシュラインに付属しているビット[39:12]の領域は物理アドレスの[39:12]と同一である。
仮想アドレスから物理アドレスの変換はTLB(Translation Look aside Buffers)の力を借りて行われる。
2-wayでのポートアクセスおよび2つのタグの比較は変換したアドレスを使って行われる。
各ポートはアドレス変換を行うための個々のTLBを持っている。

メモリ階層においてキャッシュラインの交換時には2つの64bitポートが利用される。
つまり統合L2キャッシュからL1データキャッシュへのメモリバスは128bit幅である。
新しいキャッシュラインが必要な時は、まず最初の4サイクルを利用してキャッシュラインの掃き出しが行われ、さらに4サイクルで新しいキャッシュラインがロードされてくる。

## 3.3 データキャッシュヒット/ミス検出: キャッシュタグとprimairy TLB

L1データキャッシュは、40ビットの物理アドレス空間、つまり17,179,869,184キャッシュラインのうち、1024キャッシュラインを格納するだけの能力を持つ。
キャッシュはアクセスしたい場所が、キャッシュライン中に存在しているかどうかを確認する必要がある。
このために物理アドレスの上位側を保持するための、各キャッシュラインに付属するTagRAMを使う。
2つの同時アクセスを実現するため、TagRAMは同じものを2つ保持している。

TagRAMは仮想アドレスの[14:6]ビットフィールドを用いてアクセスされる。
各TagRAMは2-wayセットアソシアティブキャッシュのうち、ヒットしたwayの番号を返す。
欲しいキャッシュラインはそのどちらかに入っている。
TagRAMは物理アドレスを保持している。
物理アドレスは、全体の分散システムメモリの中でユニークなメモリの場所を指定するのに利用される。

しかしプログラムはキャッシュに対して仮想アドレスを用いてアクセスが発生する。
仮想アドレスはプロセスのコンテキスト内でしか意味を持たない。
つまり、物理アドレスのタグをチェックするためには、「仮想アドレスから物理アドレスへの変換」が必要になる。
この変換は4つのメモリ中に存在する4つのテーブルを探索する処理が必要になる。
仮想アドレスフィールド[47:12]は4つの同じ長さのフィールドに分割され、各フィールドは4つのテーブルのインデックスとなる。
各テーブルは、次のテーブルへのポインタを保持している。
最後のテーブルがページテーブルであり、最終的な変換アドレスを保持している。

![Virtual Address to Physical Address Translation:  The Table Walk.](TableWalk.JPG)

通称テーブルウォークと呼ばれるこの処理は非常に長い時間を必要とする。
したがってOpteronはTranslation Look aside Buffers(TLB)を利用して、最近変換した40個の変換記録を保持している。
このうち32エントリが上記の機構を利用した「4kページ」の変換である。
残りの8つは、「2M/4Mページ」の変換のために利用され、最後のテーブル参照をスキップすることで2MBの大きなページを参照するために利用される。
(4MBページは過去のプロセッサと互換性を持つために利用される)。

仮想アドレス[47:12]はTLBの40エントリのすべてと比較され、これには3クロックサイクル必要である。
2サイクル目の最後には、すべてのエントリのうちどれか一つでマッチしたかどうかが分かる。
各エントリは仮想アドレスに結び付く物理アドレス[39:12]を保持している。
キャッシュヒットしたならば、これらのアドレスを3サイクル目で取得し、物理タグと比較する。

## 3.4 512エントリのセカンドレベルTLB

プライマリTLBの40エントリのうち度のラインにもヒットしなかった場合、ポートで共有しているレベル‐2 TLBにヒットする可能性がある。
テーブルには512個のアドレス変換を格納することができる。
この大きなテーブルはプライマリTLBをわずかな時間でアップデートすることができる。
このテーブルは異なる方法で構成されている。
512エントリの4-wayセットアソシアティブである。

これはつまり、4つの変換を128個保持していることと同じである。
仮想アドレスビット[18:12]は128セットのうちどのエントリを参照するかを決定する。
1つのエントリから4つの変換候補を取得することになる。
各変換には仮想アドレスの残りの領域である[47:19]が含まれる。
このアドレスとテーブル中のアドレスを比較して該当する変換が存在するかチェックする。
マッチングしたならば、所望する物理アドレスフィールド[39:12]が得られる。

## 3.5 エラーコードと訂正

L1データキャッシュはECC(Error Coding and Correction)により保護されている。
64bit枚に8ビットの訂正コードが付属しており、1ビットエラーであれば修正することができ、2ビットエラーならば発見することができる。
これには64bitのハミングSED/DED(Single Error Detection/Double Error Detection)の構成を利用している。
エラービットの位置を特定するためには、6ビットのパリティビットが必要である。

![64 bit Hamming SED/DED error location retrieval](hamming_sed_ded.JPG)

6ビットのパリティビットは上図の左側に示されている。
1はエラーが検出されたことを示している。
6ビットは32個の紫のビットのパリティを示している。
パリティエラーはエラー箇所を示す6ビットのインデックスとなっている。
さらに、パリティビットは2ビットエラーの訂正と、パリティビット自身のエラー訂正も行うことができる。

## 3.6 ロードストアユニット: LS1とLS2

ロードストアユニットはデータキャッシュへのアクセスを管理する。
このタイプのユニット禿内のアウトオブオーダプロセッサにおいて重要な役割を持つようになっている。
この領域は、新しいアーキテクチャになるにつれて、より複雑な機能を持ち、面積も急激に増加していくと予想される。
Opteronのロードストアユニットを調査するのには、もう一つの理由がある。
LS1とLS2ユニットは、しばしばLS1はL1データキャッシュであり、LS2はL2キャッシュであると説明されることが多い。
しかし、これは正確ではないどころか、実際には誤りである。
これらのユニットについてより詳細に見ていく。

![Opteron's Load Store Unit](Opteron_Load_Store_Ill.JPG)

## 3.7 「プリキャッシュド」ロードストアユニット: LS1

プリキャッシュドなロードストアユニット(LS1)はAGU(Address Generator Unit)により生成されたアドレスを待つために発行された命令によりアクセスされる。
LS1は12エントリを持ち、メモリアクセスは整数スケジューラからディスパッチされるが、LS1のエントリにもディスパッチされる。
AGUに所属しているリオーダタグバスは必要なアドレスがAGUバスの次のサイクルで入手可能であることを示すためのものである。

ある命令のアドレスがすでに入手されているならば、そのデータはキャッシュを探索する。
2つのアクセスポートが存在する。
LS1には2つのアクセスポートが存在する。
LS1に対する最も古い2つのアクセスは、キャッシュを検査することが許可される。
ロードとストア命令のどちらもキャッシュを調査する。
ロードは実際にはロードデータを取得するためにキャッシュにアクセスする。
ストアはアドレスを取得できても、その時点ではLS1に書き込みを起こさない。
ストア命令はストアするデータを取得し、その命令がリタイアしてから初めて書き込みを実施する。

ストア命令は、ストア命令自身が投機的であり、のちに破棄される可能性を考慮して、まず最初にリタイアする必要がある。
例えば、Microsoftがバッファオーバフローの弱点を修正するためにバッファオーバフローのテストをするパッチを当てたとしよう。
このテストはオーバフローが発生したときにバッファへの書き込みを防ぐための条件分岐が入っているはずだ。
オーバフローは基本的に発生しないので、分岐予測期は分岐しない方向へ常に予測する。
これはオーバフローが発生したときにも同じ状況である。バッファへの書き込みは投機的に実行されるのである。

したがって、実際のキャッシュへの書き込みは、ストア命令がリタイアし、分岐予測が正しく、そのストア命令が正しく実行されることが分かってから実行される。
しかしこれらの遅延したストア処理は、実際の遅延を発生させない。
キャッシュへアクセスする‐ロード命令はLS1とLS2をチェックし、ロードしたい場所への書き込みがペンディングされているかどうかをチェックする。
もしペンディングを発見したならば、ロード命令はLS1かLS2から直接データを読み込み、ロードの遅延が発生するのを防ぐ。

LS1へのストアには、実際にはキャッシュのヒット・ミスの検出論理が必要になる。
キャッシュラインが存在しないことが分かれば、すぐにL2キャッシュもしくはシステムメモリからデータをロードする。
これは、後続のロードが同一のキャッシュラインを要求することが多いことから、重要なチャンスである。
ストアはメモリに書き込みたいデータを受信し、LS1はデータが到着するまで待つ。そうでなければ、LS2に移動しデータを受信する。

## 3.8 LS2へのロード: キャッシュプローブレスポンス

LS1内でキャッシュのチェックをしたすべてのアクセスは、ポストキャッシュロードストアユニット(Post-Cache Load/Store Unit(LS2))に移動する。

すべてのメモリアクセスは、ロード、ストア、ロードストア(最初にロードし、同じ場所に結果をストアする)のいずれかである。
LS1から到着したすべてのアクセスは、まずキャッシュチェックの結果を待つ。これはヒットかミスのどちらかである。
キャッシュのパリティエラーが発生する可能性もある。
次にTLBにより仮想アドレスから返還した物理アドレスが得られる。
物理アドレスには、ページをキャッシング可能かどうかを示すページの属性の情報も付加されてくる。

キャッシュミスが発生すると、命令は次のサイクルでMABタグ(Missed Address Buffer Tag)と呼ばれるタグを受け取る。
このタグは後にL2もしくはシステムメモリからミスしたキャッシュラインが到着したときに利用される。
MABタグは一般的に使用されるリオーダバッファタグの代わりに利用される。
複数のロードとストアが同一のキャッシュラインに依存していると、同一のMABタグとなる。
すべてのこのようなアクセスはミス判定となり、同一のMABタグを受け取ることになる。

バスインタフェースユニット(Bus Interface Unit: BUI)はL2キャッシュもしくはシステムメモリからミスしたキャッシュラインをロードし、データキャッシュを埋める。
この時、FillタグというタグがLS2から渡される。
Fillタグはすべてのミス判定されたメモリアクセスのMABタグと比較される。
FillタグとマッチしたMABタグは、ミス判定からヒット判定へと変更される。

## 3.9 「ポストキャッシュド」ロードストアユニット: LS2

LS2はいわゆる「ポストキャッシュロードストアユニット」と呼ばれ、32エントリを持っている。
このユニットはシフトレジスタで構成され、最古のアウトスタンディングアクセスはエントリ0に到達して消去される。
各32エントリはいくつかのフィールドを持っている。
これらのフィールドの多くは、特定の条件にマッチするかをチェックするための比較器と他の論理が付属している。
すべてのアクセスはリタイアするまでLS2に滞在する。
キャッシュミスが発生した場合にはそのアクセスはLS2情でキャッシュラインがメモリ階層から到着するの待つ。
LS2で待っているすべてのストアアクセスは、リタイア処理を待っており、リタイアが完了するとメモリに書き込みを行う。

![さまざまなLS2バッファエントリ](LS2_BufferEntry.JPG)

LS2情のストア命令がリタイアすると、ヒット・ミスフラグがヒットにセットされ、LS1のストアの調査と「同時」にキャッシュポートが使用される。
LS2のリタイアしたストア処理はデータキャッシュ自身に書き込まれるが、ヒット・ミス論理は使用しない。
LS1からのストアの調査ではヒット・ミス論理を使用するだけだがデータキャッシュ自身にはアクセスしない。
この共用により重要な性能向上が達成できる。こうしなければ、1つのストアによりキャッシュのポートを2つ使用することになるからである。
一つ目はLS1によるチェックであり、2つ目はLS2によるリタイア後の書き込みである。
これによりL1データキャッシュのバンド幅が半分に抑えられてしまう。
